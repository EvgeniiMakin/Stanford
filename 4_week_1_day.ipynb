{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "* ### Non-linear Hypotheses\n",
    "https://www.coursera.org/learn/machine-learning/lecture/OAOhO/non-linear-hypotheses"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0:00\n",
    "В этом и следующем наборе видео я хотел бы рассказать вам об алгоритме обучения, называемом нейронной сетью.\n",
    "0:07\n",
    "Сначала мы поговорим о представлении, а затем в следующем наборе видео расскажем об алгоритмах обучения для него. Нейтральные сети на самом деле довольно старая идея, но на какое-то время они не понравились. Но сегодня это современная техника для многих проблем машинного обучения.\n",
    "0:23\n",
    "Итак, зачем нам нужен еще один алгоритм обучения? У нас уже есть линейная регрессия, и у нас есть логистическая регрессия, поэтому зачем нам нужны нейронные сети?\n",
    "0:32\n",
    "Чтобы мотивировать обсуждение нейронных сетей, позвольте мне начать с нескольких примеров проблем машинного обучения, где нам нужно изучить сложные нелинейные гипотезы.\n",
    "0:43\n",
    "Подумайте о контролируемой проблеме классификации обучения, где у вас есть такой набор тренировок. Если вы хотите применить логистическую регрессию к этой проблеме, одна вещь, которую вы можете сделать, это применить логическую регрессию с множеством нелинейных функций. Таким образом, g, как обычно, является сигмоидной функцией, и мы можем включать множество полиномиальных членов, подобных этим. И если вы включаете достаточно полиномиальных терминов, то, знаете, возможно, вы можете получить гипотезы\n",
    "1:11\n",
    "который отделяет положительные и отрицательные примеры. Этот конкретный метод работает хорошо, если у вас есть, скажем, две функции - x1 и x2 - потому что вы можете включить все эти полиномиальные члены x1 и x2. Но для многих интересных проблем машинного обучения было бы намного больше возможностей, чем двух.\n",
    "1:30\n",
    "Некоторое время мы говорили о предсказании жилья, и предположим, что у вас есть жилищная классификация\n",
    "1:38\n",
    "проблема, а не проблема регрессии, например, если у вас есть разные особенности дома, и вы хотите предсказать, какие шансы продать ваш дом в течение ближайших шести месяцев, так что это будет проблема классификации.\n",
    "1:52\n",
    "И, как мы видели, мы можем придумать довольно много возможностей, может быть, сотни различных особенностей разных домов.\n",
    "2:00\n",
    "Для такой проблемы, если бы вы включили все квадратичные термины, все они, даже все квадратичные, которые являются вторыми или полиномиальными членами, их было бы очень много. Были бы такие термины, как x1 в квадрате,\n",
    "2:12\n",
    "x1x2, x1x3, вы знаете, x1x4\n",
    "2:18\n",
    "до x1x100, а затем у вас есть квадрат x2, x2x3\n",
    "2:25\n",
    "и так далее. И если вы включаете только члены второго порядка, то есть термины, которые являются продуктом, вы знаете, два из этих терминов, x1 раз x1 и т. Д., Тогда для случая n равно\n",
    "2:38\n",
    "100, вы получите около пяти тысяч функций.\n",
    "2:41\n",
    "И, асимптотически, число квадратичных признаков растет примерно как квадрат порядка n, где n - количество исходных функций, таких как x1-x100, которые у нас были. И его на самом деле ближе к квадрату n над двумя.\n",
    "2:59\n",
    "Таким образом, включая все квадратичные функции, похоже, что это не очень хорошая идея, потому что у вас много возможностей, и вы можете переоборудовать набор для обучения, а также можете вычислить дорогостоящие, вы знаете,\n",
    "3:14\n",
    "работайте с множеством функций.\n",
    "3:16\n",
    "Одна вещь, которую вы можете сделать, - это только их подмножество, поэтому, если вы включите только квадраты с квадратами x1, квадраты x2, квадраты x3, возможно, в квадрат x100, то количество функций намного меньше. Здесь у вас есть только 100 таких квадратичных функций, но этого недостаточно, и, конечно же, вы не подберете такой набор данных, как в левом верхнем углу. На самом деле, если вы включите только эти квадратичные функции вместе с оригинальным x1 и т. Д., До функций x100, то вы можете фактически установить очень интересные гипотезы. Таким образом, вы можете подобрать такие вещи, как, знаете ли, доступ к линии эллипсов, подобных этим, но\n",
    "3:55\n",
    "вы, конечно, не можете подобрать более сложный набор данных, показанный здесь.\n",
    "3:59\n",
    "Таким образом, 5000 функций кажутся много, если вы должны были включить кубический или третий порядок, известный друг из друга, x1, x2, x3. Вы знаете, x1 квадрат, x2, x10 и x11, x17 и т. Д. Вы можете себе представить, что таких функций будет много. Фактически, они будут иметь порядок и куб таких функций, а если есть 100, вы можете вычислить, что в итоге вы получите порядка 170 000 таких кубических функций и, следовательно, включите эти более высокие автополиномиальные функции, когда ваш исходный набор функций конец большой, это действительно сильно разрушает ваше пространство возможностей, и это не похоже на хороший способ придумать дополнительные функции, с помощью которых невозможно построить много классификаторов, когда n велико.\n",
    "4:49\n",
    "Для многих проблем машинного обучения n будет довольно большим. Вот пример.\n",
    "4:55\n",
    "Рассмотрим проблему компьютерного зрения.\n",
    "4:59\n",
    "И предположим, что вы хотите использовать машинное обучение для обучения классификатора для изучения изображения и рассказать нам, является ли изображение автомобилем.\n",
    "5:09\n",
    "Многие люди задаются вопросом, почему компьютерное зрение может быть затруднено. Я имею в виду, когда вы и я смотрим на эту картину, это настолько очевидно, что это такое. Вы задаетесь вопросом, как может быть, что алгоритм обучения может не знать, что это за картина.\n",
    "5:22\n",
    "Чтобы понять, почему компьютерное зрение является жестким, давайте увеличим небольшую часть изображения, подобную той области, где находится маленький красный прямоугольник. Оказывается, где мы с вами видим машину, компьютер видит это. То, что он видит, это эта матрица или эта сетка значений интенсивности пикселей, которая говорит нам о яркости каждого пикселя в изображении. Поэтому проблема компьютерного зрения заключается в том, чтобы посмотреть на эту матрицу значений интенсивности пикселей и сказать, что эти цифры представляют собой дверную ручку автомобиля.\n",
    "5:54\n",
    "Конкретно, когда мы используем машинное обучение для создания автомобильного детектора, то, что мы делаем, мы придумываем набор учебных материалов для ярлыков, например, несколько примеров ярлыков автомобилей и несколько примеров ярлыков вещей, которые не являются автомобилями, а затем мы даем наш обучающий набор алгоритму обучения, обученному классификатору, а затем, вы знаете, мы можем проверить его и показать новый образ и спросить: «Что это за новая вещь?».\n",
    "6:17\n",
    "И, надеюсь, он узнает, что это автомобиль.\n",
    "6:21\n",
    "Чтобы понять, почему нам нужны нелинейные гипотезы, давайте взглянем на некоторые изображения автомобилей и, возможно, не автомобили, которые мы могли бы подкармливать нашему алгоритму обучения.\n",
    "6:32\n",
    "Давайте подберем пару пиксельных местоположений на наших изображениях, так что это пиксельное местоположение и местоположение пикселя два, и давайте построим этот автомобиль, как вы знаете, на месте в определенный момент, в зависимости от интенсивности пикселя один и пиксель два.\n",
    "6:49\n",
    "И давайте сделаем это с помощью нескольких других изображений. Итак, давайте возьмем другой пример автомобиля, и вы знаете, посмотрите на те же два пиксельных местоположения\n",
    "6:56\n",
    "и это изображение имеет разную интенсивность для пикселя и различную интенсивность для пикселя два. Таким образом, он заканчивается в другом месте на рисунке. И тогда давайте приведем некоторые негативные примеры. Это не автомобиль, это не автомобиль. И если мы делаем это для большего количества примеров, используя плюсы для обозначения автомобилей и минусов, чтобы обозначать не-автомобили, то мы обнаружим, что автомобили и не-автомобили оказываются лежащими в разных регионах пространства, и что мы поэтому необходимо найти некие нелинейные гипотезы, чтобы попытаться выделить два класса.\n",
    "7:32\n",
    "Каково измерение пространства объектов? Предположим, мы должны использовать только 50 на 50 пиксельных изображений. Теперь предположим, что наши изображения были довольно маленькими, всего 50 пикселей на стороне. Тогда у нас будет 2500 пикселей,\n",
    "7:46\n",
    "и поэтому размер нашего размера функции будет равен N, равному 2500, где наш вектор-функция x представляет собой список всех пиксельных тестов, вы знаете, яркость пикселей пикселя, яркость пикселя два и т. д. вплоть до пикселя яркость последнего пикселя, где, как вы знаете, в типичном представлении компьютера, каждый из них может быть значением между от 0 до 255, если он дает нам значение оттенков серого. Таким образом, мы имеем n равно 2500, и это, если бы мы использовали полутоновые изображения. Если бы мы использовали RGB-изображения с отдельными красными, зелеными и синими значениями, мы имели бы n равно 7500.\n",
    "8:27\n",
    "Итак, если бы мы попытались изучить нелинейную гипотезу, включив в нее все квадратичные функции, то есть все члены формы, вы знаете, Xi times Xj, в то время как с 2500 пикселями мы получим в общей сложности три миллиона функции. И это слишком велико, чтобы быть разумным; вычисление было бы очень дорогостоящим для поиска и представления всех этих трех миллионов функций на пример обучения.\n",
    "8:55  \n",
    "Таким образом, простая логистическая регрессия вместе с добавлением, возможно, квадратичных или кубических функций - это просто не лучший способ изучить сложные нелинейные гипотезы, когда n велико, потому что вы просто получаете слишком много функций. В следующих нескольких видеороликах я хотел бы рассказать вам о Neural Networks, который оказывается гораздо лучшим способом изучить сложные гипотезы, сложные нелинейные гипотезы, даже если ваше пространственное пространство ввода, даже когда n велико. И по пути я также покажу вам пару веселых видеороликов с исторически важными приложениями\n",
    "9:30\n",
    "из нейронных сетей также, что я надеюсь, что те видео, которые мы увидим позже, будут забавными для вас и для просмотра."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Neurons and the Brain\n",
    "https://www.coursera.org/learn/machine-learning/lecture/IPmzw/neurons-and-the-brain"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0:00\n",
    "Neural Networks - довольно старый алгоритм, изначально мотивированный\n",
    "0:05\n",
    "с целью иметь машины, которые могут имитировать мозг. Теперь в этом классе, конечно, я преподаю Neural Networks вам, потому что они отлично работают для разных проблем машинного обучения, а не, конечно, не потому, что они логически мотивированы.\n",
    "0:18\n",
    "В этом видео я хотел бы рассказать вам о фон Neural Networks. Чтобы мы могли понять, что мы можем ожидать от них. Как в смысле применения их к современным технологическим проблемам, так и к тем из вас, которые могут быть заинтересованы, возможно, в большой мечте AI о том, чтобы когда-нибудь построить действительно интеллектуальные машины.\n",
    "0:37\n",
    "Кроме того, как Neural Networks может относиться к этому.\n",
    "0:42\n",
    "Истоки нейронных сетей были как алгоритмы, которые пытаются имитировать мозг, и те, кто чувствует, что если мы хотим построить системы обучения, а почему бы не подражать, возможно, самой удивительной обучающей машине, о которой мы знаем, которая, возможно, является мозгом. Нейронные сети стали широко использоваться в течение 1980-х и 1990-х годов и по разным причинам, поскольку популярность уменьшилась в конце 90-х годов. Но в последнее время Нейронные сети пережили серьезное недавнее возрождение.\n",
    "1:13\n",
    "Одной из причин этого возрождения является то, что Neural Networks является вычислительным каким-то более дорогим алгоритмом, и, стало быть, вы знаете, может быть, несколько недавно, что компьютеры стали достаточно быстрыми, чтобы действительно запускать крупномасштабные нейронные сети, и из-за этого как несколько других технических причин, о которых мы поговорим позже, современные Neural Networks сегодня представляют собой современную технику для многих приложений.\n",
    "1:39\n",
    "Итак, когда вы думаете о подражании мозгу, когда один из человеческих мозгов говорит мне то же самое, не так ли? Мозг может научиться видеть образы процесса, чем слышать, учиться обрабатывать наше чувство осязания. Мы можем, вы знаете, научиться делать математику, учиться делать исчисление, а мозг делает много разных и удивительных вещей. Кажется, что если вы хотите подражать мозгу, кажется, вам нужно написать много разных программных продуктов, чтобы имитировать все эти разные увлекательные, удивительные вещи, о которых говорит нам мозг, но разве эта увлекательная гипотеза о том, что мозг все эти разные вещи не стоят тысячи различных программ, но вместо этого, как это делает мозг, стоит всего один алгоритм обучения. Это всего лишь гипотеза, но позвольте мне поделиться с вами некоторыми доказательствами этого. Эта часть мозга, эта маленькая красная часть мозга, является вашей слуховой корой и тем, как вы понимаете мой голос, теперь ваше ухо принимает звуковой сигнал и направляет звуковой сигнал в вашу слуховую кору, и это то, что позволяет вам чтобы понять мои слова.\n",
    "2:41\n",
    "Neuroscientists сделали следующие увлекательные эксперименты, где вы отрезаете провод от ушей до слуховой коры и вы повторно подключаетесь,\n",
    "2:50\n",
    "в этом случае мозг животного, так что сигнал от глаз к зрительному нерву в конечном итоге направляется в слуховую кору.\n",
    "2:58\n",
    "Если вы сделаете это, оказывается, слуховая кора будет учиться\n",
    "3:02\n",
    "видеть. И это в каждом смысле этого слова понимают, как мы это знаем. Итак, если вы делаете это с животными, животные могут выполнять задачу визуальной дискриминации, и они могут смотреть на изображения и принимать соответствующие решения на основе изображений, и они делают это с помощью этой части ткани мозга.\n",
    "3:19\n",
    "Вот еще один пример.\n",
    "3:21\n",
    "Эта красная часть ткани мозга - ваша соматосенсорная кора. Вот как вы обрабатываете свое осязание. Если вы выполните аналогичный процесс повторной проводки\n",
    "3:30\n",
    "то соматосенсорная кора будет учиться видеть. Из-за этого и других подобных экспериментов, они называются нейро-rewiring эксперименты.\n",
    "3:39\n",
    "Есть такое ощущение, что если один и тот же кусок физической ткани мозга может обрабатывать зрение или звук или прикосновение, то, возможно, есть один алгоритм обучения, который может обрабатывать зрение, звук или прикосновение. И вместо того, чтобы выполнять тысячу различных программ или тысячи разных алгоритмов, вы знаете, тысячи замечательных вещей, которые делает мозг, может быть, нам нужно сделать некоторое приближение или что бы ни был алгоритм обучения мозга реализовать это и что мозг сам научился обрабатывать эти разные типы данных.\n",
    "4:13\n",
    "В удивительно большой степени кажется, что мы можем подключить почти любой датчик практически к любой части мозга, и поэтому, по этой причине, мозг научится справляться с этим.\n",
    "4:25\n",
    "Вот еще несколько примеров. В левом верхнем углу - пример обучения, который вы видите своим языком. То, как это работает, - это на самом деле система под названием BrainPort, которая сейчас проходит испытания FDA, чтобы помочь слепым людям увидеть, - но, как это работает, вы привязываете камеру на полу, чтобы смотреть на ваш лоб, лицом вперед, который принимает оттенки серого с низким разрешением образ того, что перед вами, и вы затем запустите провод\n",
    "4:51\n",
    "к множеству электродов, которые вы размещаете на своем языке, чтобы каждый пиксель отображался на месте на вашем языке, где, возможно, высокое напряжение соответствует темному пикселю, а низкое напряжение соответствует яркому пикселю и, как и сегодня, с такой системой вы и я сможем узнать, как вы знаете, через десятки минут с нашими языками. Вот второй пример местоположения человеческого эха или человеческого сонара.\n",
    "5:19\n",
    "Таким образом, вы можете сделать это двумя способами. Вы можете щелкнуть пальцами,\n",
    "5:24\n",
    "или нажмите язык. Я не могу сделать это очень хорошо. Но сегодня есть слепые люди, которые на самом деле обучаются в школах, чтобы сделать это, и научиться интерпретировать образец звуков, отскакивающих от вашей среды - это сонар. Итак, если после поиска на YouTube есть видео этого удивительного ребенка, который трагически из-за рака удалил глазные яблоки, так что это ребенок без глазных яблок. Но, щелкая пальцами, он может ходить и никогда ничего не бить. Он может кататься на скейтборде. Он может стрелять в баскетбол в обруч, и это ребенок без глазных яблок.\n",
    "6:00\n",
    "Третий пример - Хэппический пояс, где, если у вас есть ремешок вокруг вашей талии, звоните в шумные звонки, и у вас всегда есть самый северный гудок. Вы можете дать человеку направление, похожее на то, как птицы могут, знаете ли, понять, где находится север. И некоторые из странных примеров, но если вы подключите третий глаз к лягушке, лягушка научится использовать этот глаз.\n",
    "6:27\n",
    "Таким образом, это довольно удивительно, насколько вы можете подключить почти любой датчик к мозгу, и алгоритм обучения мозга будет просто определять, как учиться на этих данных и обрабатывать эти данные.\n",
    "6:40\n",
    "И есть смысл, что, если мы сможем понять, что такое алгоритм обучения мозга, и, знаете ли, реализовать его или реализовать некоторое приближение к этому алгоритму на компьютере, возможно, это был бы наш лучший шанс, вы знаете, добились реального прогресса к ИИ, мечту искусственного интеллекта о том, чтобы когда-нибудь построить действительно интеллектуальные машины.\n",
    "6:59\n",
    "Теперь, конечно, я не преподаю Neural Networks, вы знаете, просто потому, что они могут дать нам окно в этот далекий меч, хотя я лично, это одна из тех вещей, над которыми я лично работаю моя исследовательская жизнь. Но главная причина, по которой я преподаю Neural Networks в этом классе, состоит в том, что на самом деле это очень эффективная современная техника для современных приложений для машинного обучения. Итак, в следующих нескольких видеороликах мы начнем погружение в технические детали Neural Networks, чтобы вы могли применить их к современным приложениям для машинного обучения и заставить их хорошо работать над проблемами. Но для меня, вы знаете, одна из причин меня возбуждает, что, возможно, они дают нам это окно в то, что мы можем сделать, если мы также будем думать о том, какие алгоритмы могут когда-нибудь научиться способом, подобным человечеству."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

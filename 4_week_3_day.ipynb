{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Examples and Intuitions I\n",
    "https://www.coursera.org/learn/machine-learning/supplement/kivO9/examples-and-intuitions-i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0:00\n",
    "В этом и следующем видео я хочу работать с подробным примером, показывающим, как нейронная сеть может вычислять сложную нелинейную функцию ввода. И, надеюсь, это даст вам хорошее представление о том, почему нейронные сети могут использоваться для изучения сложных нелинейных гипотез. Рассмотрим следующую проблему, где у нас есть функции X1 и X2, которые являются двоичными значениями. Итак, либо 0, либо 1. Итак, X1 и X2 могут принимать только одно из двух возможных значений. В этом примере я нарисовал только два положительных примера и два отрицательных примера. То, что вы можете рассматривать это как упрощенную версию более сложной проблемы обучения, где у нас может быть множество положительных примеров в правом верхнем и нижнем левом и куча негативных примеров, обозначенных кругами. И то, что мы хотели бы сделать, это изучить нелинейное разделение границы, которое может потребовать отделить положительные и отрицательные примеры.\n",
    "0:53\n",
    "Итак, как нейронная сеть может это сделать, а вместо использования примера и переменной использовать это, возможно, проще изучить пример слева. Конкретно, что это такое, действительно вычисляет тип метки y, равный x 1 x или x 2. Или фактически это фактически функция x 1 x или x 2, где x и не является альтернативным обозначением для не x 1 или x 2. Итак , x 1 x или x 2, это верно, только если ровно 1 из x 1 или x 2 равно 1. Получается, что эти конкретные примеры в работе немного лучше, если вместо этого мы используем пример XNOR. Разумеется, эти два одинаковы. Это означает, что нет x1 или x2, и поэтому мы будем иметь положительные примеры обоих значений: true, или оба являются ложными, а то, что имеет y, равно 1, y равно 1. И мы будем иметь y равно 0, если только один из них верен, и мы собираемся выяснить, можем ли мы получить нейронную сеть, соответствующую этому набору тренировок.\n",
    "1:59\n",
    "Чтобы создать сеть, подходящую для примера XNOR, мы начнем с немного более простой и покажем сеть, которая соответствует функции И. Конкретно, допустим, у нас есть вход x1 и x2, которые снова являются бинарниками, так что это либо 0, либо 1, и предположим, что наши целевые метки y = x1 AND x2. Это логическое И.\n",
    "2:30\n",
    "Итак, можно ли получить единую сеть для вычисления этой логической функции И? Для этого я собираюсь фактически нарисовать блок смещения, а также плюс один блок.\n",
    "2:45\n",
    "Теперь позвольте мне просто присвоить некоторые значения весам или параметрам этой сети. Я собираюсь записать параметры на этой диаграмме здесь, -30 здесь. +20 и + 20. И что это означает, что я назначаю значение -30 для значения, связанного с X0, это +1, входящее в этот блок, и значение параметра +20, которое умножает на X1 значение + 20 для параметра, который умножается на x 2. Итак, конкретно, это то же самое, что гипотеза h (x) = g (-30 + 20 X1 плюс 20 X2. Поэтому иногда просто удобно рисовать эти веса. здесь на диаграмме внутри и, конечно, это 30. Это фактически тета 1 из 1 0. Это тета 1 из 1 1, и это тета 1 из 1 2, но просто легче подумать об этом, связав эти параметры с ребрами сети.\n",
    "4:01\n",
    "Давайте посмотрим, что вычислит эта небольшая сеть нейронов. Чтобы напомнить вам, сигмоидная функция активации g (z) выглядит так. Он начинается с 0, плавно пересекает 0,5, а затем он асимптотически равен 1 и дает вам некоторые ориентиры, если значение горизонтальной оси z равно 4.6, тогда сигмоидальная функция равна 0,99. Это очень близко к 1 и относится к симметрично, если это -4,6, тогда сигмоидальная функция равна 0,01, что очень близко к 0. Рассмотрим четыре возможных входных значения для x1 и x2 и посмотрим, какие гипотезы будут выводиться в в этом случае. Если x1 и x2 равны 0. Если вы посмотрите на это, если x1 x2 равны 0, то гипотеза g of -30. Таким образом, это очень далеко слева от этой диаграммы, поэтому оно будет очень близко к 0. Если x 1 равно 0, а x равно 1, то эта формула здесь оценивает g, которая является сигма-функцией, примененной к -10, и снова это вы знаете в крайнем левом углу этого сюжета, и вот, это снова очень близко к 0.\n",
    "5:17\n",
    "Это также g минус 10, что fx 1 равно 1 и x 2 0, это минус 30 плюс 20, что составляет минус 10, и, наконец, если x 1 равно 1 x 2 равно 1, тогда у вас есть g минус 30 плюс 20 плюс 20. Итак, это g положительных 10, которые существуют очень близко к 1.\n",
    "5:39\n",
    "И если вы посмотрите в этом столбце, это как раз логика и функция. Таким образом, это вычисление h из x приблизительно равно x 1 и x 2. Иными словами, он выводит один. Если и только если x2, x1 и x2 равны 1. Таким образом, выписав нашу маленькую таблицу истинности, как это, удается определить, что такое логическая функция, которую вычисляет наша нейронная сеть. Эта сеть, показанная здесь, вычисляет функцию ИЛИ. Просто чтобы показать, как я это сделал. Если вы выписываете гипотезу о том, что это запутывающее g из -10 + 20 x 1 + 20 x 2 и поэтому вы заполняете эти значения. Вы находите, что это g минус 10, что составляет приблизительно 0. g из 10, что приблизительно равно 1 и так далее, и это приблизительно 1 и приблизительно 1, и эти числа являются по существу логической функцией OR.\n",
    "6:49\n",
    "Итак, надеюсь, с этим вы теперь поймете, как одиночные нейроны в нейронной сети могут использоваться для вычисления логических функций, таких как AND и OR, и так далее. В следующем видео мы продолжим работу над этими примерами и рассмотрим более сложный пример. Мы покажем вам, как можно использовать нейронную сеть с несколькими уровнями единиц для вычисления более сложных функций, таких как функция XOR или функция XNOR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Examples and Intuitions II\n",
    "https://www.coursera.org/learn/machine-learning/supplement/5iqtV/examples-and-intuitions-ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0:00\n",
    "В этом видео я бы хотел продолжить работу над нашим примером, чтобы показать, как нейронная сеть может вычислить сложную нелинейную гипотезу.\n",
    "0:10\n",
    "В последнем видео мы видели, как Neural Network может использоваться для вычисления функций x1 и x2, а функция x1 OR x2, когда x1 и x2 двоичные, то есть когда они принимают значения 0,1. Мы можем также иметь сеть для вычисления отрицания, то есть для вычисления функции not x1. Позвольте мне просто записать способы, связанные с этой сетью. В этом случае у нас есть только одна функция ввода x1 и единица смещения +1. И если я свяжу это с весами плюс 10 и -20, то моя гипотеза вычисляет, что h (x) равно сигмоиду (10-20 x1). Поэтому, когда x1 равно 0, моя гипотеза будет вычислять g (10-20 x 0) как раз 10. И так, что примерно 1, а когда x равно 1, это будет g (-10), что приблизительно равным 0. И если вы посмотрите на то, что эти значения, это по существу не функция x1. Клетки включают отрицания, общая идея состоит в том, чтобы поставить этот большой отрицательный вес перед переменной, которую вы хотите скрыть. Минус 20 умножается на x1, и это общая идея о том, как вы заканчиваете отрицание x1. И вот в одном примере, на который я надеюсь, что вы сами сможете понять. Если вы хотите вычислить такую функцию, как NOT x1 AND NOT x2, часть этого, вероятно, будет помещать большие отрицательные веса перед x1 и x2, но это должно быть осуществимо. Таким образом, вы можете получить нейронную сеть только с одним модулем вывода, чтобы вычислить это. Хорошо, поэтому эта логическая функция NOT x1 AND NOT x2 будет равна 1 тогда и только тогда, когда\n",
    "2:06\n",
    "x1 равно x2 равно 0. Хорошо, так как это логическая функция, это говорит, что NOT x1 означает, что x1 должен быть 0 и NOT x2, что означает, что x2 также должно быть равно 0. Таким образом, эта логическая функция равна 1 тогда и только тогда, когда оба x1 и x2 равны 0, и, надеюсь, вы должны выяснить, как сделать небольшую нейронную сеть для вычисления этой логической функции.\n",
    "2:33\n",
    "Теперь, взяв три части, которые мы собрали в качестве сети для вычисления x1 и x2, и вычислительные сети для вычисления NOT x1 AND NOT x2. И последнее сетевое вычисление для вычисления x1 OR x2, мы должны собрать эти три части для вычисления этой функции x1 XNOR x2. И просто чтобы напомнить вам, является ли это x1, x2, эта функция, которую мы хотим вычислить, будет иметь отрицательные примеры здесь и здесь, и у нас были бы положительные примеры там и там. И поэтому ясно, что для разделения положительных и отрицательных примеров потребуется граница нелинейного решения.\n",
    "3:12\n",
    "Давайте нарисуем сеть. Я возьму свой ввод +1, x1, x2 и создаю свой первый скрытый блок здесь. Я собираюсь назвать это 21 cuz, это моя первая скрытая единица. И я собираюсь скопировать вес из красной сети, x1 и x2. Так вот, тогда -30, 20, 20. Далее позвольте мне создать вторую скрытую единицу, которую я собираюсь назвать 2 2. Это вторая скрытая единица второго уровня. Я собираюсь скопировать поверх голубого, что работает в середине, так что у меня будут весы 10 -20 -20. Итак, давайте потянем некоторые значения таблицы истинности. Для красной сети мы знаем, что вычисляли x1 и x2, и поэтому это будет приблизительно 0 0 0 1, в зависимости от значений x1 и x2, а для a 2 2 - голубой сети. Что мы знаем? Функция NOT x1 AND NOT x2, которая выводит 1 0 0 0, для 4 значений x1 и x2.\n",
    "4:18\n",
    "Наконец, я собираюсь создать свой выходной узел, мой модуль вывода - это 3 1. Это еще один выход h (x), и я собираюсь скопировать его по старой сети. И здесь мне понадобится блок смещения +1, поэтому вы нарисуете это, И я собираюсь скопировать весы из зеленых сетей. Итак, это -10, 20, 20, и мы знаем ранее, что это вычисляет функцию ИЛИ.\n",
    "4:46\n",
    "Итак, давайте заполним записи таблицы истинности.\n",
    "4:50\n",
    "Таким образом, первая запись равна 0 OR 1, которая может быть 1, которая делает 0 ИЛИ 0, которая равна 0, 0 ИЛИ 0, которая равна 0, 1 OR 0 и которая падает до 1. И, следовательно, h (x) равен 1, когда оба x1 и x2 равны нулю или когда x1 и x2 равны 1 и конкретно h (x) выдает 1 точно в этих двух местах, а затем выводит 0 в противном случае.\n",
    "5:19\n",
    "И, таким образом, эта нейронная сеть, у которой есть входной уровень, один скрытый слой и один выходной уровень, заканчивается нелинейной границей решения, которая вычисляет эту функцию XNOR. И более общая интуиция заключается в том, что во входном слое у нас есть только четыре входа. Тогда у нас есть скрытый слой, который вычисляет несколько несколько более сложные функции входов, которые здесь показаны здесь, это несколько более сложные функции. И затем, добавив еще один слой, мы получим еще более сложную нелинейную функцию.\n",
    "5:50\n",
    "И это своего рода интуиция о том, почему нейронные сети могут вычислять довольно сложные функции. То, что, когда у вас есть несколько уровней, вы имеете относительно простую функцию входов второго слоя. Но третий слой, который я могу построить на этом, чтобы завершить еще более сложные функции, а затем слой после этого может вычислить еще более сложные функции.\n",
    "6:10\n",
    "Чтобы завершить это видео, я хочу показать вам забавный пример приложения нейронной сети, который захватывает эту интуицию более глубоких слоев, вычисляя более сложные функции. Я хочу показать вам видео этого клиента, моего хорошего друга Яна ЛеКуна. Янн - профессор Нью-Йоркского университета, Нью-Йоркский университет, и он был одним из первых пионеров исследования Neural Network и сейчас является своего рода легендой в этой области, и его идеи используются во всех видах продуктов и приложений во всем мире.\n",
    "6:41\n",
    "Поэтому я хочу показать вам видео с его ранней работы, в которой он использовал нейронную сеть для распознавания рукописного ввода, для распознавания рукописных цифр. Вы могли бы вспомнить на ранней стадии этого класса, в начале этого класса я сказал, что один из ранних успехов нейронных сетей пытался использовать его для чтения почтовых индексов, чтобы помочь законам USPS и читать почтовые коды. Так что это одна из попыток, это один из алгоритмов, используемых для решения этой проблемы. В видео, которое я покажу вам, эта область здесь - область ввода, в которой отображается отображаемый символ, отображаемый в сети. В этом столбце показана визуализация функций, вычисленных в виде первого скрытого уровня сети. Так что первый скрытый слой сети и, таким образом, первый скрытый слой, эта визуализация показывает разные функции. Различные ребра и линии и т. Д. Обнаружены. Это визуализация следующего скрытого слоя. Это гораздо труднее увидеть, труднее понять более глубокие, скрытые слои, и это визуализация того, почему следующий скрытый слой запутан. Вероятно, вам нелегко видеть, что происходит намного дальше первого скрытого слоя, но затем, наконец, все эти изученные функции получают питание на верхний уровень. И приведенный здесь окончательный ответ, это конечная прогностическая ценность того, что рукописная цифра, которую нейронная сеть думает, что она показана. Итак, давайте посмотрим на видео. [МУЗЫКА]\n",
    "9:49\n",
    "Поэтому я надеюсь, что вам понравилось видео, и это, надеюсь, дало вам некоторую интуицию об источнике довольно сложных функций, которые могут научить нейронные сети. В котором он берет свой ввод этого изображения, просто берет этот вход, необработанные пиксели и первый скрытый слой вычисляет некоторый набор функций. Следующий скрытый слой вычисляет еще более сложные функции и даже более сложные функции. И эти функции затем могут быть использованы, по существу, последним слоем логистических классификаторов для точного прогнозирования без номеров, которые видит сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Multiclass Classification\n",
    "https://www.coursera.org/learn/machine-learning/supplement/xSUml/multiclass-classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
